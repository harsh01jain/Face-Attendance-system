{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "617d083c-fac2-4b7c-b1e0-874d8e4dd924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import face_recognition\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d60f2a98-bd47-4c20-a298-009fa001cb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Harsh_1.jpg', 'Harsh_2.jpg', 'Harsh_3.jpg', 'Harsh_4.jpg', 'Harsh_5.jpg', 'janak_1.jpg', 'janak_2.jpg', 'janak_3.jpg', 'janak_4.jpg', 'janak_5.jpg']\n",
      "['Harsh', 'Harsh', 'Harsh', 'Harsh', 'Harsh', 'janak', 'janak', 'janak', 'janak', 'janak']\n"
     ]
    }
   ],
   "source": [
    "path = r\"C:\\Users\\Harsh\\Pictures\\ImageAttendance\"\n",
    "images = []\n",
    "classnames = []\n",
    "\n",
    "# Get list of image files from the directory\n",
    "myList = os.listdir(path)\n",
    "print(myList)\n",
    "\n",
    "for cl in myList:\n",
    "    curImg = cv2.imread(f\"{path}/{cl}\")  # Read the image\n",
    "    images.append(curImg)  # Add the image to the list\n",
    "\n",
    "    # Extract the name before the underscore, e.g., \"harsh\" from \"harsh_1\"\n",
    "    name = os.path.splitext(cl)[0].split('_')[0]\n",
    "    classnames.append(name)  # Append the base name (without number)\n",
    "\n",
    "print(classnames)  # Check the list of names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c77963d7-7195-4035-b907-2007609abf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findEncodings(images):\n",
    "    encodelist = []  # List to store encodings\n",
    "    for img in images:\n",
    "        # Convert the image from BGR (OpenCV format) to RGB (face_recognition format)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Find face encodings for the current image\n",
    "        encodes = face_recognition.face_encodings(img)\n",
    "        \n",
    "        # If a face encoding was found, append it to the list\n",
    "        if len(encodes) > 0:\n",
    "            encodelist.append(encodes[0])\n",
    "        else:\n",
    "            print(\"No face found in image, skipping...\")\n",
    "    \n",
    "    return encodelist  # Return after all images are processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34ac1eea-9669-46a8-af78-a7b2f29bea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def markAttendance(name):\n",
    "    with open('Attendance.csv', 'r+') as f:\n",
    "        myDataList = f.readlines()  # Read all existing lines in the CSV\n",
    "        nameList = []  # A list to store all the names already recorded\n",
    "\n",
    "        # Extract names from each line and add them to nameList\n",
    "        for line in myDataList:\n",
    "            entry = line.split(',')  # Split line by comma to get the name\n",
    "            nameList.append(entry[0])  # Append only the name (first item)\n",
    "\n",
    "        # If the name is not already in the file, write it to the file\n",
    "        if name not in nameList:\n",
    "            now = datetime.now()  # Get the current time\n",
    "            dtString = now.strftime('%H:%M:%S')  # Format the time as HH:MM:SS\n",
    "            f.write(f'\\n{name},{dtString}')  # Write name and time to the file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72a2acf0-922a-4e61-9d20-a675c9344646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face found in image, skipping...\n",
      "No face found in image, skipping...\n",
      "No face found in image, skipping...\n",
      "Encoding complete\n"
     ]
    }
   ],
   "source": [
    "encodelistknown = findEncodings(images)\n",
    "print (\"Encoding complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "223247ce-3a01-41bc-a3f7-58f77e56e97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()  \n",
    "    if not success:\n",
    "        break  \n",
    "\n",
    "    imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)  # Resize for faster processing\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)  # Convert to RGB as face_recognition uses RGB\n",
    "\n",
    "    facesCurFrame = face_recognition.face_locations(imgS)  # Detect face locations\n",
    "    encodesCurFrame = face_recognition.face_encodings(imgS, facesCurFrame)  # Get face encodings\n",
    "\n",
    "    for encodeFace, faceLoc in zip(encodesCurFrame, facesCurFrame):\n",
    "        matches = face_recognition.compare_faces(encodelistknown, encodeFace)\n",
    "        faceDis = face_recognition.face_distance(encodelistknown, encodeFace)\n",
    "        matchIndex = np.argmin(faceDis)\n",
    "\n",
    "        # If a match is found\n",
    "        if matches[matchIndex]:\n",
    "            name = classnames[matchIndex].upper()  # Get the name of the matched person\n",
    "        else:\n",
    "            name = \"Unknown\"  # If no match, label as \"Unknown\"\n",
    "\n",
    "        y1, x2, y2, x1 = faceLoc  # Unpack face location\n",
    "        y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4  # Scale back to original size\n",
    "\n",
    "        # Draw rectangle around the face\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)    \n",
    "        # Draw filled rectangle below the face for the name\n",
    "        cv2.rectangle(img, (x1, y2 - 35), (x2, y2), (0, 255, 0), cv2.FILLED)\n",
    "        # Put the name below the face\n",
    "        cv2.putText(img, name, (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "        # Call markAttendance only if the person is recognized (not \"Unknown\")\n",
    "        if name != \"Unknown\":\n",
    "            markAttendance(name)\n",
    "\n",
    "    # Show the webcam image\n",
    "    cv2.imshow('Webcam', img)\n",
    "\n",
    "    # Break loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()  # Release the webcam\n",
    "cv2.destroyAllWindows()  # Close all OpenCV windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7b4ebc-e367-4d4c-bcce-7305791afca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
